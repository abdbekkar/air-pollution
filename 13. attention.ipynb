{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memory footprint support libraries/code\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# !pip install psutil\n",
    "# !pip install humanize\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/zafir/miniconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional, RepeatVector, Dot, Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import mse\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_input_data = np.load('./data/third-order/seq2seq/train_encoder_input_data.npy')\n",
    "train_decoder_input_data = np.load('./data/third-order/seq2seq/train_decoder_input_data.npy')\n",
    "train_decoder_target_data = np.load('./data/third-order/seq2seq/train_decoder_target_data.npy')\n",
    "\n",
    "valid_encoder_input_data = np.load('./data/third-order/seq2seq/valid_encoder_input_data.npy')\n",
    "valid_decoder_input_data = np.load('./data/third-order/seq2seq/valid_decoder_input_data.npy')\n",
    "valid_decoder_target_data = np.load('./data/third-order/seq2seq/valid_decoder_target_data.npy')\n",
    "\n",
    "test_encoder_input_data = np.load('./data/third-order/seq2seq/test_encoder_input_data.npy')\n",
    "test_decoder_input_data = np.load('./data/third-order/seq2seq/test_decoder_input_data.npy')\n",
    "test_decoder_target_data = np.load('./data/third-order/seq2seq/test_decoder_target_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the model architecture, we need to transform the output shape and type\n",
    "train_decoder_target_data = list(np.swapaxes(train_decoder_target_data, 0, 1))\n",
    "valid_decoder_target_data = list(np.swapaxes(valid_decoder_target_data, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67396, 24, 23)\n",
      "(67396, 12, 23)\n",
      "12 (67396, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_encoder_input_data.shape)\n",
    "print(train_decoder_input_data.shape)\n",
    "print(len(train_decoder_target_data), train_decoder_target_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, encoder_input_dim = (train_encoder_input_data.shape[1], \n",
    "                         train_encoder_input_data.shape[2])\n",
    "    \n",
    "Ty, decoder_input_dim = (train_decoder_input_data.shape[1], \n",
    "                         train_decoder_input_data.shape[2])\n",
    "\n",
    "# we are predicting the pollution only, leave out the mask\n",
    "decoder_output_dim = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 250\n",
    "max_trials = 250\n",
    "executions_per_trial = 1\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(encoder_outputs, h_prev, attention_repeat, \n",
    "                       attention_concatenate, attention_dense_1,\n",
    "                       attention_dense_2, attention_activation,\n",
    "                       attention_dot):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed \n",
    "    as a dot product of the attention weights \"alphas\" and the outputs\n",
    "    of the encoder.\n",
    "    \n",
    "    Arguments:\n",
    "    encoder_outputs -- outputs of the encoder, numpy-array of shape \n",
    "                       (m, Tx, 2*encoder_latent_dim)\n",
    "    h_prev -- previous hidden state of the decoder LSTM, numpy-array \n",
    "              of shape (m, decoder_latent_dim)\n",
    "    attention_repeat -- predefined repeat layer for the attention\n",
    "    attention_concatenate -- predefined concatenate layer for the \n",
    "                             attention\n",
    "    attention_dense_1 -- predefined dense layer for the attention\n",
    "    attention_dense_2 -- predefined dense layer for the attention\n",
    "    attention_activation -- predefined activation layer for the \n",
    "                            attention\n",
    "    attention_dot -- predefined dot layer for the attention\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input to the decoder LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Repeat h_prev to be of shape (m, Tx, decoder_latent_dim) \n",
    "    h_prev = attention_repeat(h_prev)\n",
    "    \n",
    "    # Concatenate the encoder outputs to the repeated vector\n",
    "    concat = attention_concatenate([encoder_outputs, h_prev])\n",
    "       \n",
    "    # Compute the energies\n",
    "    energies = attention_dense_1(concat)\n",
    "    energies = attention_dense_2(energies)\n",
    "\n",
    "    # Compute the alphas by applying softmax on the energies\n",
    "    alphas = attention_activation(energies)\n",
    "\n",
    "    # Compute the context vector by dotting the alphas and \n",
    "    # the encoder outputs\n",
    "    context = attention_dot([alphas, encoder_outputs])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, decoder_input_dim, \n",
    "                 decoder_output_dim):\n",
    "        \"\"\"\n",
    "        Constructor for the derived HyperModel class\n",
    "        \n",
    "        Arguments:\n",
    "        Tx -- length of the input sequence\n",
    "        Ty -- length of the output sequence\n",
    "        encoder_input_dim -- length of input vector for the encoder\n",
    "        decoder_input_dim -- length of input vector for the decoder\n",
    "        decoder_output_dim -- length of output vector for the decoder\n",
    "        \"\"\"\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "\n",
    "    def build(self, hp):\n",
    "        \"\"\"\n",
    "        Builds a seq2seq LSTM model with an attention mechanism. \n",
    "\n",
    "        Arguments:\n",
    "        hp -- hyperparameters object from keras-tuner\n",
    "\n",
    "        Returns:\n",
    "        model -- Keras model instance\n",
    "        \"\"\"\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        encoder_latent_dim = hp.Int('encoder_latent_dim', min_value=16, max_value=48, \n",
    "                                    step=16)\n",
    "        decoder_latent_dim = 2 * encoder_latent_dim\n",
    "        attention_dense_dim = hp.Int('attention_dense_dim', min_value=8, max_value=14, \n",
    "                                     step=2)\n",
    "\n",
    "        # Encoder layers\n",
    "        encoder_lstm = Bidirectional(LSTM(encoder_latent_dim, return_sequences=True, \n",
    "                                          name='encoder_lstm'), merge_mode='concat')\n",
    "\n",
    "        # Attention layers\n",
    "        attention_repeat = RepeatVector(self.Tx, name='attention_repeat')\n",
    "        attention_concatenate = Concatenate(axis=-1, name='attention_concatenate')\n",
    "        attention_dense_1 = Dense(attention_dense_dim, activation='tanh', \n",
    "                                  name='attention_dense_1')\n",
    "        attention_dense_2 = Dense(1, activation='relu', name='attention_dense_2')\n",
    "        attention_activation = Activation(softmax, name='attention_activation') \n",
    "        attention_dot = Dot(axes = 1)\n",
    "\n",
    "        # Decoder layers\n",
    "        decoder_concatenate = Concatenate(axis=-1, name='decoder_concatenate')\n",
    "        decoder_lstm = LSTM(decoder_latent_dim, return_state=True, \n",
    "                            name='decoder_lstm')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, activation='linear',\n",
    "                              name='decoder_dense')\n",
    "\n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Encoder inputs\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        encoder_outputs = encoder_lstm(encoder_inputs)\n",
    "\n",
    "        # Decoder inputs\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Zeros tensors as initial values for h and c.\n",
    "        # Basically, I apply the decoder LSTM on the first timestep of encoder outputs  \n",
    "        # concatenated with decoder inputs in order to get the hidden states h and c, \n",
    "        # and then I create zeros tensors from their shape, because I cannot obtain \n",
    "        # the batch size dynamically. Moreover, I have to apply an identity lambda \n",
    "        # function in order to cast the zero tensor to a Keras tensor (otherwise it \n",
    "        # cannot be passed as initial_state)\n",
    "\n",
    "        # x is a slice of the encoder outputs\n",
    "        x = Lambda(lambda x: x[:, 0, :])(encoder_outputs)\n",
    "        x = K.expand_dims(x, axis=1)\n",
    "        # y is a slice of the decoder inputs\n",
    "        y = Lambda(lambda y: y[:, 0, :])(decoder_inputs)\n",
    "        y = K.expand_dims(y, axis=1)\n",
    "        # z is a concatenation of x and y\n",
    "        z = Concatenate(axis=-1)([x, y])\n",
    "        # we feed the dummy tensor in order to obtain a sample tensor of h and c\n",
    "        _, h, c = decoder_lstm(z)\n",
    "        # create tensors of zeros using the shapes of the previous dummies\n",
    "        h = Lambda(lambda x: x, name='h0')(K.zeros_like(h))\n",
    "        c = Lambda(lambda x: x, name='c0')(K.zeros_like(c))\n",
    "\n",
    "        # Decoder outputs\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(self.Ty):\n",
    "            # Perform attention for one timestep\n",
    "            context = one_step_attention(encoder_outputs, h, attention_repeat, \n",
    "                                         attention_concatenate, attention_dense_1,\n",
    "                                         attention_dense_2, attention_activation,\n",
    "                                         attention_dot)\n",
    "            \n",
    "            # Concatenate the context vector and the decoder input\n",
    "            decoder_input = Lambda(lambda x: x[:, t, :])(decoder_inputs)\n",
    "            decoder_input = K.expand_dims(decoder_input, axis=1)\n",
    "            full_decoder_input = decoder_concatenate([context, decoder_input])\n",
    "\n",
    "            # Apply post-attention LSTM\n",
    "            h, _, c = decoder_lstm(inputs=full_decoder_input, initial_state=[h, c])\n",
    "\n",
    "            # Apply dense to compute the output\n",
    "            decoder_output = decoder_dense(h)\n",
    "            \n",
    "            # Append the the model's outputs\n",
    "            outputs.append(decoder_output)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=attention_masked_mse)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project local-keras-tuner/attention/test/oracle.json\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = AttentionModel(Tx, Ty, encoder_input_dim, decoder_input_dim,\n",
    "                                decoder_output_dim)\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/attention', \n",
    "                     project_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f7a3e5e8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f7a3e5e8400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f7a3e5e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f7a3e5e8488>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/zafir/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 67396 samples, validate on 3388 samples\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1344/67396 [..............................] - ETA: 1:52:32 - loss: 16.0021 - decoder_dense_loss: 1.1840 - decoder_dense_1_loss: 1.2867 - decoder_dense_2_loss: 1.3426 - decoder_dense_3_loss: 1.5244 - decoder_dense_4_loss: 1.4441 - decoder_dense_5_loss: 1.4496 - decoder_dense_6_loss: 1.4035 - decoder_dense_7_loss: 1.2620 - decoder_dense_8_loss: 1.1125 - decoder_dense_9_loss: 1.1917 - decoder_dense_10_loss: 1.3735 - decoder_dense_11_loss: 1.427 - ETA: 57:07 - loss: 13.9686 - decoder_dense_loss: 0.9185 - decoder_dense_1_loss: 0.9271 - decoder_dense_2_loss: 0.9632 - decoder_dense_3_loss: 1.0529 - decoder_dense_4_loss: 1.0734 - decoder_dense_5_loss: 1.2203 - decoder_dense_6_loss: 1.2647 - decoder_dense_7_loss: 1.2765 - decoder_dense_8_loss: 1.2466 - decoder_dense_9_loss: 1.2357 - decoder_dense_10_loss: 1.3824 - decoder_dense_11_loss: 1.4072  - ETA: 38:33 - loss: 13.8532 - decoder_dense_loss: 0.7992 - decoder_dense_1_loss: 0.7715 - decoder_dense_2_loss: 0.8116 - decoder_dense_3_loss: 0.9666 - decoder_dense_4_loss: 1.0006 - decoder_dense_5_loss: 1.1945 - decoder_dense_6_loss: 1.3037 - decoder_dense_7_loss: 1.3355 - decoder_dense_8_loss: 1.3358 - decoder_dense_9_loss: 1.3417 - decoder_dense_10_loss: 1.4773 - decoder_dense_11_loss: 1.514 - ETA: 29:19 - loss: 11.2394 - decoder_dense_loss: 0.7303 - decoder_dense_1_loss: 0.6404 - decoder_dense_2_loss: 0.6498 - decoder_dense_3_loss: 0.7706 - decoder_dense_4_loss: 0.8073 - decoder_dense_5_loss: 0.9537 - decoder_dense_6_loss: 1.0390 - decoder_dense_7_loss: 1.0748 - decoder_dense_8_loss: 1.0725 - decoder_dense_9_loss: 1.0822 - decoder_dense_10_loss: 1.1934 - decoder_dense_11_loss: 1.225 - ETA: 23:44 - loss: 9.8480 - decoder_dense_loss: 0.6787 - decoder_dense_1_loss: 0.5741 - decoder_dense_2_loss: 0.5794 - decoder_dense_3_loss: 0.6768 - decoder_dense_4_loss: 0.7168 - decoder_dense_5_loss: 0.8299 - decoder_dense_6_loss: 0.8902 - decoder_dense_7_loss: 0.9227 - decoder_dense_8_loss: 0.9425 - decoder_dense_9_loss: 0.9393 - decoder_dense_10_loss: 1.0384 - decoder_dense_11_loss: 1.059 - ETA: 20:09 - loss: 9.1567 - decoder_dense_loss: 0.6434 - decoder_dense_1_loss: 0.5492 - decoder_dense_2_loss: 0.5545 - decoder_dense_3_loss: 0.6330 - decoder_dense_4_loss: 0.6660 - decoder_dense_5_loss: 0.7584 - decoder_dense_6_loss: 0.8181 - decoder_dense_7_loss: 0.8421 - decoder_dense_8_loss: 0.8548 - decoder_dense_9_loss: 0.8757 - decoder_dense_10_loss: 0.9814 - decoder_dense_11_loss: 0.98 - ETA: 17:32 - loss: 8.4437 - decoder_dense_loss: 0.6315 - decoder_dense_1_loss: 0.5352 - decoder_dense_2_loss: 0.5326 - decoder_dense_3_loss: 0.6033 - decoder_dense_4_loss: 0.6434 - decoder_dense_5_loss: 0.6971 - decoder_dense_6_loss: 0.7415 - decoder_dense_7_loss: 0.7537 - decoder_dense_8_loss: 0.7677 - decoder_dense_9_loss: 0.7889 - decoder_dense_10_loss: 0.8761 - decoder_dense_11_loss: 0.87 - ETA: 15:32 - loss: 8.1142 - decoder_dense_loss: 0.6124 - decoder_dense_1_loss: 0.5155 - decoder_dense_2_loss: 0.5151 - decoder_dense_3_loss: 0.5859 - decoder_dense_4_loss: 0.6129 - decoder_dense_5_loss: 0.6716 - decoder_dense_6_loss: 0.7191 - decoder_dense_7_loss: 0.7282 - decoder_dense_8_loss: 0.7392 - decoder_dense_9_loss: 0.7593 - decoder_dense_10_loss: 0.8272 - decoder_dense_11_loss: 0.82 - ETA: 13:59 - loss: 7.6673 - decoder_dense_loss: 0.5990 - decoder_dense_1_loss: 0.5024 - decoder_dense_2_loss: 0.4924 - decoder_dense_3_loss: 0.5547 - decoder_dense_4_loss: 0.5808 - decoder_dense_5_loss: 0.6397 - decoder_dense_6_loss: 0.6786 - decoder_dense_7_loss: 0.6819 - decoder_dense_8_loss: 0.6917 - decoder_dense_9_loss: 0.7073 - decoder_dense_10_loss: 0.7560 - decoder_dense_11_loss: 0.78 - ETA: 12:44 - loss: 7.2627 - decoder_dense_loss: 0.5842 - decoder_dense_1_loss: 0.4822 - decoder_dense_2_loss: 0.4620 - decoder_dense_3_loss: 0.5194 - decoder_dense_4_loss: 0.5483 - decoder_dense_5_loss: 0.6030 - decoder_dense_6_loss: 0.6494 - decoder_dense_7_loss: 0.6442 - decoder_dense_8_loss: 0.6584 - decoder_dense_9_loss: 0.6703 - decoder_dense_10_loss: 0.7108 - decoder_dense_11_loss: 0.73 - ETA: 11:44 - loss: 6.8377 - decoder_dense_loss: 0.5723 - decoder_dense_1_loss: 0.4652 - decoder_dense_2_loss: 0.4405 - decoder_dense_3_loss: 0.4881 - decoder_dense_4_loss: 0.5134 - decoder_dense_5_loss: 0.5603 - decoder_dense_6_loss: 0.6031 - decoder_dense_7_loss: 0.6080 - decoder_dense_8_loss: 0.6161 - decoder_dense_9_loss: 0.6241 - decoder_dense_10_loss: 0.6649 - decoder_dense_11_loss: 0.68 - ETA: 10:52 - loss: 6.4584 - decoder_dense_loss: 0.5452 - decoder_dense_1_loss: 0.4401 - decoder_dense_2_loss: 0.4158 - decoder_dense_3_loss: 0.4638 - decoder_dense_4_loss: 0.4834 - decoder_dense_5_loss: 0.5270 - decoder_dense_6_loss: 0.5678 - decoder_dense_7_loss: 0.5700 - decoder_dense_8_loss: 0.5801 - decoder_dense_9_loss: 0.5896 - decoder_dense_10_loss: 0.6318 - decoder_dense_11_loss: 0.64 - ETA: 10:10 - loss: 6.2315 - decoder_dense_loss: 0.5282 - decoder_dense_1_loss: 0.4167 - decoder_dense_2_loss: 0.4077 - decoder_dense_3_loss: 0.4481 - decoder_dense_4_loss: 0.4619 - decoder_dense_5_loss: 0.5048 - decoder_dense_6_loss: 0.5462 - decoder_dense_7_loss: 0.5499 - decoder_dense_8_loss: 0.5635 - decoder_dense_9_loss: 0.5726 - decoder_dense_10_loss: 0.6107 - decoder_dense_11_loss: 0.62 - ETA: 9:33 - loss: 5.9636 - decoder_dense_loss: 0.5155 - decoder_dense_1_loss: 0.4002 - decoder_dense_2_loss: 0.3886 - decoder_dense_3_loss: 0.4260 - decoder_dense_4_loss: 0.4384 - decoder_dense_5_loss: 0.4819 - decoder_dense_6_loss: 0.5195 - decoder_dense_7_loss: 0.5275 - decoder_dense_8_loss: 0.5443 - decoder_dense_9_loss: 0.5479 - decoder_dense_10_loss: 0.5843 - decoder_dense_11_loss: 0.5896 - ETA: 9:01 - loss: 5.7478 - decoder_dense_loss: 0.5061 - decoder_dense_1_loss: 0.3902 - decoder_dense_2_loss: 0.3766 - decoder_dense_3_loss: 0.4088 - decoder_dense_4_loss: 0.4208 - decoder_dense_5_loss: 0.4623 - decoder_dense_6_loss: 0.4972 - decoder_dense_7_loss: 0.5083 - decoder_dense_8_loss: 0.5263 - decoder_dense_9_loss: 0.5267 - decoder_dense_10_loss: 0.5589 - decoder_dense_11_loss: 0.565 - ETA: 8:32 - loss: 5.4865 - decoder_dense_loss: 0.4893 - decoder_dense_1_loss: 0.3720 - decoder_dense_2_loss: 0.3587 - decoder_dense_3_loss: 0.3935 - decoder_dense_4_loss: 0.4056 - decoder_dense_5_loss: 0.4425 - decoder_dense_6_loss: 0.4740 - decoder_dense_7_loss: 0.4849 - decoder_dense_8_loss: 0.4994 - decoder_dense_9_loss: 0.5008 - decoder_dense_10_loss: 0.5296 - decoder_dense_11_loss: 0.536 - ETA: 8:09 - loss: 5.2779 - decoder_dense_loss: 0.4760 - decoder_dense_1_loss: 0.3575 - decoder_dense_2_loss: 0.3449 - decoder_dense_3_loss: 0.3760 - decoder_dense_4_loss: 0.3894 - decoder_dense_5_loss: 0.4244 - decoder_dense_6_loss: 0.4542 - decoder_dense_7_loss: 0.4674 - decoder_dense_8_loss: 0.4802 - decoder_dense_9_loss: 0.4840 - decoder_dense_10_loss: 0.5092 - decoder_dense_11_loss: 0.514 - ETA: 7:48 - loss: 5.1059 - decoder_dense_loss: 0.4651 - decoder_dense_1_loss: 0.3478 - decoder_dense_2_loss: 0.3380 - decoder_dense_3_loss: 0.3694 - decoder_dense_4_loss: 0.3774 - decoder_dense_5_loss: 0.4117 - decoder_dense_6_loss: 0.4380 - decoder_dense_7_loss: 0.4481 - decoder_dense_8_loss: 0.4603 - decoder_dense_9_loss: 0.4665 - decoder_dense_10_loss: 0.4890 - decoder_dense_11_loss: 0.494 - ETA: 7:27 - loss: 4.9415 - decoder_dense_loss: 0.4532 - decoder_dense_1_loss: 0.3389 - decoder_dense_2_loss: 0.3313 - decoder_dense_3_loss: 0.3617 - decoder_dense_4_loss: 0.3696 - decoder_dense_5_loss: 0.3973 - decoder_dense_6_loss: 0.4236 - decoder_dense_7_loss: 0.4325 - decoder_dense_8_loss: 0.4436 - decoder_dense_9_loss: 0.4467 - decoder_dense_10_loss: 0.4686 - decoder_dense_11_loss: 0.474 - ETA: 7:11 - loss: 4.7601 - decoder_dense_loss: 0.4381 - decoder_dense_1_loss: 0.3254 - decoder_dense_2_loss: 0.3189 - decoder_dense_3_loss: 0.3510 - decoder_dense_4_loss: 0.3598 - decoder_dense_5_loss: 0.3832 - decoder_dense_6_loss: 0.4088 - decoder_dense_7_loss: 0.4147 - decoder_dense_8_loss: 0.4261 - decoder_dense_9_loss: 0.4280 - decoder_dense_10_loss: 0.4496 - decoder_dense_11_loss: 0.456 - ETA: 6:54 - loss: 4.6005 - decoder_dense_loss: 0.4234 - decoder_dense_1_loss: 0.3149 - decoder_dense_2_loss: 0.3096 - decoder_dense_3_loss: 0.3404 - decoder_dense_4_loss: 0.3479 - decoder_dense_5_loss: 0.3704 - decoder_dense_6_loss: 0.3966 - decoder_dense_7_loss: 0.4004 - decoder_dense_8_loss: 0.4101 - decoder_dense_9_loss: 0.4121 - decoder_dense_10_loss: 0.4342 - decoder_dense_11_loss: 0.4406"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2176/67396 [..............................] - ETA: 6:41 - loss: 4.4712 - decoder_dense_loss: 0.4186 - decoder_dense_1_loss: 0.3081 - decoder_dense_2_loss: 0.3009 - decoder_dense_3_loss: 0.3295 - decoder_dense_4_loss: 0.3371 - decoder_dense_5_loss: 0.3578 - decoder_dense_6_loss: 0.3827 - decoder_dense_7_loss: 0.3881 - decoder_dense_8_loss: 0.4000 - decoder_dense_9_loss: 0.4001 - decoder_dense_10_loss: 0.4202 - decoder_dense_11_loss: 0.428 - ETA: 6:27 - loss: 4.3694 - decoder_dense_loss: 0.4155 - decoder_dense_1_loss: 0.3033 - decoder_dense_2_loss: 0.2947 - decoder_dense_3_loss: 0.3199 - decoder_dense_4_loss: 0.3277 - decoder_dense_5_loss: 0.3505 - decoder_dense_6_loss: 0.3726 - decoder_dense_7_loss: 0.3812 - decoder_dense_8_loss: 0.3912 - decoder_dense_9_loss: 0.3896 - decoder_dense_10_loss: 0.4079 - decoder_dense_11_loss: 0.415 - ETA: 6:14 - loss: 4.2531 - decoder_dense_loss: 0.4054 - decoder_dense_1_loss: 0.3023 - decoder_dense_2_loss: 0.2909 - decoder_dense_3_loss: 0.3128 - decoder_dense_4_loss: 0.3178 - decoder_dense_5_loss: 0.3387 - decoder_dense_6_loss: 0.3622 - decoder_dense_7_loss: 0.3702 - decoder_dense_8_loss: 0.3784 - decoder_dense_9_loss: 0.3777 - decoder_dense_10_loss: 0.3945 - decoder_dense_11_loss: 0.402 - ETA: 6:03 - loss: 4.1385 - decoder_dense_loss: 0.3954 - decoder_dense_1_loss: 0.2945 - decoder_dense_2_loss: 0.2825 - decoder_dense_3_loss: 0.3037 - decoder_dense_4_loss: 0.3084 - decoder_dense_5_loss: 0.3294 - decoder_dense_6_loss: 0.3525 - decoder_dense_7_loss: 0.3597 - decoder_dense_8_loss: 0.3679 - decoder_dense_9_loss: 0.3677 - decoder_dense_10_loss: 0.3838 - decoder_dense_11_loss: 0.393 - ETA: 5:52 - loss: 4.0329 - decoder_dense_loss: 0.3895 - decoder_dense_1_loss: 0.2871 - decoder_dense_2_loss: 0.2737 - decoder_dense_3_loss: 0.2953 - decoder_dense_4_loss: 0.2992 - decoder_dense_5_loss: 0.3218 - decoder_dense_6_loss: 0.3453 - decoder_dense_7_loss: 0.3513 - decoder_dense_8_loss: 0.3594 - decoder_dense_9_loss: 0.3572 - decoder_dense_10_loss: 0.3723 - decoder_dense_11_loss: 0.380 - ETA: 5:42 - loss: 3.9508 - decoder_dense_loss: 0.3802 - decoder_dense_1_loss: 0.2805 - decoder_dense_2_loss: 0.2677 - decoder_dense_3_loss: 0.2916 - decoder_dense_4_loss: 0.2919 - decoder_dense_5_loss: 0.3142 - decoder_dense_6_loss: 0.3383 - decoder_dense_7_loss: 0.3439 - decoder_dense_8_loss: 0.3549 - decoder_dense_9_loss: 0.3493 - decoder_dense_10_loss: 0.3648 - decoder_dense_11_loss: 0.373 - ETA: 5:32 - loss: 3.8445 - decoder_dense_loss: 0.3710 - decoder_dense_1_loss: 0.2725 - decoder_dense_2_loss: 0.2609 - decoder_dense_3_loss: 0.2838 - decoder_dense_4_loss: 0.2836 - decoder_dense_5_loss: 0.3053 - decoder_dense_6_loss: 0.3288 - decoder_dense_7_loss: 0.3337 - decoder_dense_8_loss: 0.3442 - decoder_dense_9_loss: 0.3394 - decoder_dense_10_loss: 0.3579 - decoder_dense_11_loss: 0.363 - ETA: 5:23 - loss: 3.7451 - decoder_dense_loss: 0.3615 - decoder_dense_1_loss: 0.2656 - decoder_dense_2_loss: 0.2543 - decoder_dense_3_loss: 0.2764 - decoder_dense_4_loss: 0.2772 - decoder_dense_5_loss: 0.2980 - decoder_dense_6_loss: 0.3192 - decoder_dense_7_loss: 0.3248 - decoder_dense_8_loss: 0.3355 - decoder_dense_9_loss: 0.3309 - decoder_dense_10_loss: 0.3478 - decoder_dense_11_loss: 0.353 - ETA: 5:15 - loss: 3.6555 - decoder_dense_loss: 0.3528 - decoder_dense_1_loss: 0.2585 - decoder_dense_2_loss: 0.2493 - decoder_dense_3_loss: 0.2687 - decoder_dense_4_loss: 0.2714 - decoder_dense_5_loss: 0.2914 - decoder_dense_6_loss: 0.3109 - decoder_dense_7_loss: 0.3191 - decoder_dense_8_loss: 0.3271 - decoder_dense_9_loss: 0.3234 - decoder_dense_10_loss: 0.3388 - decoder_dense_11_loss: 0.343 - ETA: 5:07 - loss: 3.5744 - decoder_dense_loss: 0.3462 - decoder_dense_1_loss: 0.2534 - decoder_dense_2_loss: 0.2451 - decoder_dense_3_loss: 0.2645 - decoder_dense_4_loss: 0.2647 - decoder_dense_5_loss: 0.2846 - decoder_dense_6_loss: 0.3039 - decoder_dense_7_loss: 0.3111 - decoder_dense_8_loss: 0.3192 - decoder_dense_9_loss: 0.3153 - decoder_dense_10_loss: 0.3307 - decoder_dense_11_loss: 0.335 - ETA: 5:00 - loss: 3.5033 - decoder_dense_loss: 0.3384 - decoder_dense_1_loss: 0.2486 - decoder_dense_2_loss: 0.2407 - decoder_dense_3_loss: 0.2592 - decoder_dense_4_loss: 0.2603 - decoder_dense_5_loss: 0.2817 - decoder_dense_6_loss: 0.2984 - decoder_dense_7_loss: 0.3046 - decoder_dense_8_loss: 0.3116 - decoder_dense_9_loss: 0.3083 - decoder_dense_10_loss: 0.3238 - decoder_dense_11_loss: 0.327 - ETA: 4:54 - loss: 3.4305 - decoder_dense_loss: 0.3314 - decoder_dense_1_loss: 0.2443 - decoder_dense_2_loss: 0.2364 - decoder_dense_3_loss: 0.2575 - decoder_dense_4_loss: 0.2556 - decoder_dense_5_loss: 0.2752 - decoder_dense_6_loss: 0.2914 - decoder_dense_7_loss: 0.2975 - decoder_dense_8_loss: 0.3049 - decoder_dense_9_loss: 0.3010 - decoder_dense_10_loss: 0.3161 - decoder_dense_11_loss: 0.319 - ETA: 4:47 - loss: 3.3625 - decoder_dense_loss: 0.3261 - decoder_dense_1_loss: 0.2404 - decoder_dense_2_loss: 0.2310 - decoder_dense_3_loss: 0.2520 - decoder_dense_4_loss: 0.2539 - decoder_dense_5_loss: 0.2703 - decoder_dense_6_loss: 0.2851 - decoder_dense_7_loss: 0.2906 - decoder_dense_8_loss: 0.2979 - decoder_dense_9_loss: 0.2943 - decoder_dense_10_loss: 0.3084 - decoder_dense_11_loss: 0.3124"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-55cd88cc1ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[EarlyStopping(monitor='val_loss', \n\u001b[1;32m     11\u001b[0m                                       \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                       verbose=1)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
