{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memory footprint support libraries/code\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# !pip install psutil\n",
    "# !pip install humanize\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models import *\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_input_data = np.load('./data/third-order/Centar/train_encoder_input_data.npy')\n",
    "train_decoder_input_data = np.load('./data/third-order/Centar/train_decoder_input_data.npy')\n",
    "train_decoder_target_data = np.load('./data/third-order/Centar/train_decoder_target_data.npy')\n",
    "\n",
    "valid_encoder_input_data = np.load('./data/third-order/Centar/valid_encoder_input_data.npy')\n",
    "valid_decoder_input_data = np.load('./data/third-order/Centar/valid_decoder_input_data.npy')\n",
    "valid_decoder_target_data = np.load('./data/third-order/Centar/valid_decoder_target_data.npy')\n",
    "\n",
    "test_encoder_input_data = np.load('./data/third-order/Centar/test_encoder_input_data.npy')\n",
    "test_decoder_input_data = np.load('./data/third-order/Centar/test_decoder_input_data.npy')\n",
    "test_decoder_target_data = np.load('./data/third-order/Centar/test_decoder_target_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the model architecture, we need to transform the output shape and type\n",
    "train_decoder_target_data = list(np.swapaxes(train_decoder_target_data, 0, 1))\n",
    "valid_decoder_target_data = list(np.swapaxes(valid_decoder_target_data, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_encoder_input_data.shape)\n",
    "print(train_decoder_input_data.shape)\n",
    "print((len(train_decoder_target_data),) + train_decoder_target_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, encoder_input_dim = (train_encoder_input_data.shape[1], \n",
    "                         train_encoder_input_data.shape[2])\n",
    "    \n",
    "Ty, decoder_input_dim = (train_decoder_input_data.shape[1], \n",
    "                         train_decoder_input_data.shape[2])\n",
    "\n",
    "# we are predicting the pollution only, leave out the mask\n",
    "decoder_output_dim = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 250\n",
    "max_trials = 1000\n",
    "executions_per_trial = 1\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = AttentiveSeq2Seq(Tx, Ty, encoder_input_dim, decoder_input_dim,\n",
    "                                decoder_output_dim)\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='attentive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             verbose=0,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1),\n",
    "                        LossPrintingCallback(Ty)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
