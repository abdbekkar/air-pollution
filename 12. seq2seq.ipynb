{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architectures\n",
    "- simple (encoder: lstm, decoder: lstm -> dense)\n",
    "- stacked (encoder: lstm -> lstm, decoder: lstm -> dense)\n",
    "- bistacked (encoder: bilstm -> lstm, decoder: lstm -> dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memory footprint support libraries/code\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# !pip install psutil\n",
    "# !pip install humanize\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/third-order/X_train.npy')\n",
    "y_train = np.load('./data/third-order/y_train.npy')\n",
    "X_valid = np.load('./data/third-order/X_valid.npy')\n",
    "y_valid = np.load('./data/third-order/y_valid.npy')\n",
    "X_test = np.load('./data/third-order/X_test.npy')\n",
    "y_test = np.load('./data/third-order/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, encoder_input_dim = X_train.shape[1], X_train.shape[2]\n",
    "Ty = y_train.shape[1]\n",
    "# we feed back only the target variable we are predicting\n",
    "decoder_input_dim = decoder_output_dim = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_encoder_input_data = X_train.copy()\n",
    "train_decoder_target_data = y_train.copy()\n",
    "train_decoder_input_data = shift(train_decoder_target_data[:, :, 0].reshape(\n",
    "                                y_train.shape[0], y_train.shape[1], decoder_input_dim), \n",
    "                           shift=[0, 1, 0], cval=-10)\n",
    "\n",
    "valid_encoder_input_data = X_valid.copy()\n",
    "valid_decoder_target_data = y_valid.copy()\n",
    "valid_decoder_input_data = shift(valid_decoder_target_data[:, :, 0].reshape(\n",
    "                                y_valid.shape[0], y_valid.shape[1], decoder_input_dim), \n",
    "                           shift=[0, 1, 0], cval=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "    return K.sum(((y_true[:, :, 0] - y_pred[:, :, 0]) ** 2) * (1-y_true[:, :, 1]), \n",
    "                  axis=-1) / (1 + K.sum((1-y_true[:, :, 1]), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=16, max_value=64, step=16)\n",
    "        \n",
    "        encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        dropout = Dropout(rate=hp.Float('dropout', 0, 0.5, \n",
    "                                        step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        \n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "\n",
    "        # We discard output and keep the states only.\n",
    "        _, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = SimpleSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Train on 67397 samples, validate on 3389 samples\n",
      "Epoch 1/100\n",
      "14208/67397 [=====>........................] - ETA: 15:42 - loss: 0.86 - ETA: 5:32 - loss: 0.6133 - ETA: 3:30 - loss: 0.495 - ETA: 2:19 - loss: 0.406 - ETA: 1:46 - loss: 0.362 - ETA: 1:34 - loss: 0.338 - ETA: 1:27 - loss: 0.320 - ETA: 1:26 - loss: 0.310 - ETA: 1:20 - loss: 0.296 - ETA: 1:14 - loss: 0.287 - ETA: 1:07 - loss: 0.276 - ETA: 1:04 - loss: 0.266 - ETA: 59s - loss: 0.256 - ETA: 55s - loss: 0.24 - ETA: 52s - loss: 0.23 - ETA: 51s - loss: 0.23 - ETA: 51s - loss: 0.23 - ETA: 50s - loss: 0.23 - ETA: 47s - loss: 0.22 - ETA: 46s - loss: 0.21 - ETA: 46s - loss: 0.21 - ETA: 45s - loss: 0.21 - ETA: 44s - loss: 0.20 - ETA: 42s - loss: 0.20 - ETA: 41s - loss: 0.19 - ETA: 40s - loss: 0.19 - ETA: 39s - loss: 0.19 - ETA: 38s - loss: 0.18 - ETA: 37s - loss: 0.18 - ETA: 38s - loss: 0.18 - ETA: 38s - loss: 0.18 - ETA: 37s - loss: 0.17 - ETA: 36s - loss: 0.17 - ETA: 36s - loss: 0.17 - ETA: 35s - loss: 0.17 - ETA: 35s - loss: 0.16 - ETA: 35s - loss: 0.16 - ETA: 34s - loss: 0.16 - ETA: 34s - loss: 0.16 - ETA: 34s - loss: 0.16 - ETA: 33s - loss: 0.16 - ETA: 32s - loss: 0.15 - ETA: 32s - loss: 0.15 - ETA: 32s - loss: 0.15 - ETA: 31s - loss: 0.15 - ETA: 31s - loss: 0.15 - ETA: 30s - loss: 0.14 - ETA: 30s - loss: 0.14 - ETA: 30s - loss: 0.14 - ETA: 30s - loss: 0.14 - ETA: 29s - loss: 0.14 - ETA: 29s - loss: 0.14 - ETA: 29s - loss: 0.14 - ETA: 29s - loss: 0.14 - ETA: 29s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 28s - loss: 0.13 - ETA: 27s - loss: 0.13 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 27s - loss: 0.12 - ETA: 26s - loss: 0.12 - ETA: 26s - loss: 0.12 - ETA: 26s - loss: 0.12 - ETA: 26s - loss: 0.12 - ETA: 26s - loss: 0.12 - ETA: 26s - loss: 0.12 - ETA: 26s - loss: 0.11 - ETA: 25s - loss: 0.11 - ETA: 25s - loss: 0.11 - ETA: 25s - loss: 0.11 - ETA: 25s - loss: 0.11 - ETA: 25s - loss: 0.11 - ETA: 25s - loss: 0.11 - ETA: 24s - loss: 0.11 - ETA: 24s - loss: 0.11 - ETA: 24s - loss: 0.11 - ETA: 24s - loss: 0.11 - ETA: 24s - loss: 0.11 - ETA: 24s - loss: 0.1135"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d5a2ee902cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[EarlyStopping(monitor='val_loss', \n\u001b[1;32m     11\u001b[0m                                       \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                       verbose=1)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        encoder_latent_dim = hp.Int('encoder_latent_dim', min_value=32, \n",
    "                                    max_value=128, step=32)\n",
    "        shared_latent_dim = hp.Int('shared_latent_dim', min_value=32, \n",
    "                                   max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = LSTM(encoder_latent_dim, return_sequences=True, \n",
    "                              name='encoder_lstm_1')\n",
    "        encoder_dropout = Dropout(rate=hp.Float('encoder_dropout', 0, 0.7, \n",
    "                                        step=0.1, default=0.5))\n",
    "        encoder_lstm_2 = LSTM(shared_latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm = LSTM(shared_latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dropout = Dropout(rate=hp.Float('decoder_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # Obtain the outputs from the first encoder layer\n",
    "        encoder_out = encoder_lstm_1(encoder_inputs) \n",
    "        \n",
    "        # Pass the outputs through a dropout layer before \n",
    "        # feeding them to the next LSTM layer\n",
    "        encoder_out = encoder_dropout(encoder_out)\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm_2(encoder_out)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = decoder_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = StackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='stacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Train on 67397 samples, validate on 3389 samples\n",
      "Epoch 1/100\n",
      " 4032/67397 [>.............................] - ETA: 27:20 - loss: 0.77 - ETA: 14:35 - loss: 0.78 - ETA: 10:15 - loss: 0.86 - ETA: 8:11 - loss: 0.8822 - ETA: 6:53 - loss: 0.879 - ETA: 6:06 - loss: 0.871 - ETA: 5:32 - loss: 0.821 - ETA: 5:05 - loss: 0.821 - ETA: 4:40 - loss: 0.796 - ETA: 4:22 - loss: 0.757 - ETA: 4:07 - loss: 0.757 - ETA: 3:55 - loss: 0.760 - ETA: 3:44 - loss: 0.739 - ETA: 3:34 - loss: 0.718 - ETA: 3:27 - loss: 0.699 - ETA: 3:22 - loss: 0.681 - ETA: 3:17 - loss: 0.665 - ETA: 3:11 - loss: 0.647 - ETA: 3:05 - loss: 0.636 - ETA: 3:01 - loss: 0.622 - ETA: 2:56 - loss: 0.616 - ETA: 2:53 - loss: 0.607 - ETA: 2:49 - loss: 0.597 - ETA: 2:46 - loss: 0.586 - ETA: 2:43 - loss: 0.572 - ETA: 2:40 - loss: 0.563 - ETA: 2:38 - loss: 0.558 - ETA: 2:36 - loss: 0.548 - ETA: 2:34 - loss: 0.542 - ETA: 2:34 - loss: 0.535 - ETA: 2:34 - loss: 0.525 - ETA: 2:34 - loss: 0.517 - ETA: 2:32 - loss: 0.509 - ETA: 2:30 - loss: 0.501 - ETA: 2:29 - loss: 0.494 - ETA: 2:29 - loss: 0.487 - ETA: 2:29 - loss: 0.481 - ETA: 2:28 - loss: 0.480 - ETA: 2:28 - loss: 0.478 - ETA: 2:27 - loss: 0.474 - ETA: 2:26 - loss: 0.468 - ETA: 2:25 - loss: 0.464 - ETA: 2:25 - loss: 0.458 - ETA: 2:24 - loss: 0.455 - ETA: 2:24 - loss: 0.450 - ETA: 2:25 - loss: 0.445 - ETA: 2:26 - loss: 0.443 - ETA: 2:26 - loss: 0.440 - ETA: 2:26 - loss: 0.436 - ETA: 2:25 - loss: 0.431 - ETA: 2:24 - loss: 0.427 - ETA: 2:23 - loss: 0.424 - ETA: 2:22 - loss: 0.422 - ETA: 2:23 - loss: 0.418 - ETA: 2:22 - loss: 0.414 - ETA: 2:22 - loss: 0.410 - ETA: 2:20 - loss: 0.407 - ETA: 2:19 - loss: 0.403 - ETA: 2:18 - loss: 0.400 - ETA: 2:17 - loss: 0.397 - ETA: 2:16 - loss: 0.393 - ETA: 2:16 - loss: 0.390 - ETA: 2:16 - loss: 0.3879"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d5a2ee902cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[EarlyStopping(monitor='val_loss', \n\u001b[1;32m     11\u001b[0m                                       \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                       verbose=1)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiStackedSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        encoder_latent_dim = hp.Int('encoder_latent_dim', min_value=32, \n",
    "                                    max_value=128, step=32)\n",
    "        shared_latent_dim = hp.Int('shared_latent_dim', min_value=32, \n",
    "                                   max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = Bidirectional(LSTM(encoder_latent_dim, return_sequences=True, \n",
    "                              name='encoder_lstm_1'))\n",
    "        encoder_dropout = Dropout(rate=hp.Float('encoder_dropout', 0, 0.7, \n",
    "                                        step=0.1, default=0.5))\n",
    "        encoder_lstm_2 = LSTM(shared_latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm = LSTM(shared_latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dropout = Dropout(rate=hp.Float('decoder_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # Obtain the outputs from the first encoder layer\n",
    "        encoder_out = encoder_lstm_1(encoder_inputs) \n",
    "        \n",
    "        # Pass the outputs through a dropout layer before \n",
    "        # feeding them to the next LSTM layer\n",
    "        encoder_out = encoder_dropout(encoder_out)\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm_2(encoder_out)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = decoder_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = BiStackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='bistacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f4ea4f1b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f4ea4f1b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f4ea4f1b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f4ea4f1b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Train on 67397 samples, validate on 3389 samples\n",
      "Epoch 1/100\n",
      "11712/67397 [====>.........................] - ETA: 31:04 - loss: 1.12 - ETA: 16:35 - loss: 0.78 - ETA: 11:34 - loss: 0.66 - ETA: 9:07 - loss: 0.5638 - ETA: 7:38 - loss: 0.507 - ETA: 6:45 - loss: 0.466 - ETA: 6:04 - loss: 0.435 - ETA: 5:32 - loss: 0.413 - ETA: 5:07 - loss: 0.389 - ETA: 4:44 - loss: 0.375 - ETA: 4:31 - loss: 0.358 - ETA: 4:18 - loss: 0.350 - ETA: 4:10 - loss: 0.336 - ETA: 4:00 - loss: 0.323 - ETA: 3:51 - loss: 0.312 - ETA: 3:43 - loss: 0.300 - ETA: 3:36 - loss: 0.296 - ETA: 3:29 - loss: 0.291 - ETA: 3:23 - loss: 0.283 - ETA: 3:18 - loss: 0.277 - ETA: 3:13 - loss: 0.274 - ETA: 3:09 - loss: 0.270 - ETA: 3:08 - loss: 0.263 - ETA: 3:05 - loss: 0.261 - ETA: 3:01 - loss: 0.255 - ETA: 2:59 - loss: 0.251 - ETA: 2:55 - loss: 0.248 - ETA: 2:52 - loss: 0.244 - ETA: 2:51 - loss: 0.241 - ETA: 2:49 - loss: 0.237 - ETA: 2:48 - loss: 0.234 - ETA: 2:47 - loss: 0.231 - ETA: 2:45 - loss: 0.229 - ETA: 2:43 - loss: 0.227 - ETA: 2:41 - loss: 0.224 - ETA: 2:40 - loss: 0.220 - ETA: 2:39 - loss: 0.217 - ETA: 2:38 - loss: 0.217 - ETA: 2:39 - loss: 0.214 - ETA: 2:40 - loss: 0.212 - ETA: 2:43 - loss: 0.209 - ETA: 2:43 - loss: 0.208 - ETA: 2:43 - loss: 0.206 - ETA: 2:42 - loss: 0.203 - ETA: 2:41 - loss: 0.201 - ETA: 2:40 - loss: 0.199 - ETA: 2:39 - loss: 0.197 - ETA: 2:37 - loss: 0.195 - ETA: 2:36 - loss: 0.194 - ETA: 2:35 - loss: 0.192 - ETA: 2:34 - loss: 0.191 - ETA: 2:33 - loss: 0.189 - ETA: 2:33 - loss: 0.188 - ETA: 2:32 - loss: 0.187 - ETA: 2:32 - loss: 0.185 - ETA: 2:31 - loss: 0.183 - ETA: 2:30 - loss: 0.181 - ETA: 2:29 - loss: 0.180 - ETA: 2:28 - loss: 0.178 - ETA: 2:27 - loss: 0.177 - ETA: 2:26 - loss: 0.175 - ETA: 2:25 - loss: 0.174 - ETA: 2:24 - loss: 0.173 - ETA: 2:24 - loss: 0.172 - ETA: 2:24 - loss: 0.171 - ETA: 2:24 - loss: 0.170 - ETA: 2:23 - loss: 0.169 - ETA: 2:22 - loss: 0.168 - ETA: 2:22 - loss: 0.167 - ETA: 2:22 - loss: 0.167 - ETA: 2:21 - loss: 0.166 - ETA: 2:20 - loss: 0.165 - ETA: 2:19 - loss: 0.165 - ETA: 2:19 - loss: 0.164 - ETA: 2:18 - loss: 0.163 - ETA: 2:18 - loss: 0.162 - ETA: 2:17 - loss: 0.161 - ETA: 2:16 - loss: 0.160 - ETA: 2:16 - loss: 0.160 - ETA: 2:15 - loss: 0.159 - ETA: 2:15 - loss: 0.158 - ETA: 2:14 - loss: 0.157 - ETA: 2:14 - loss: 0.157 - ETA: 2:14 - loss: 0.156 - ETA: 2:13 - loss: 0.155 - ETA: 2:13 - loss: 0.154 - ETA: 2:12 - loss: 0.153 - ETA: 2:12 - loss: 0.153 - ETA: 2:11 - loss: 0.152 - ETA: 2:10 - loss: 0.152 - ETA: 2:10 - loss: 0.151 - ETA: 2:09 - loss: 0.150 - ETA: 2:09 - loss: 0.150 - ETA: 2:09 - loss: 0.149 - ETA: 2:08 - loss: 0.148 - ETA: 2:08 - loss: 0.148 - ETA: 2:07 - loss: 0.148 - ETA: 2:07 - loss: 0.147 - ETA: 2:07 - loss: 0.146 - ETA: 2:07 - loss: 0.145 - ETA: 2:07 - loss: 0.145 - ETA: 2:06 - loss: 0.144 - ETA: 2:06 - loss: 0.144 - ETA: 2:05 - loss: 0.143 - ETA: 2:05 - loss: 0.143 - ETA: 2:04 - loss: 0.142 - ETA: 2:04 - loss: 0.142 - ETA: 2:04 - loss: 0.141 - ETA: 2:04 - loss: 0.141 - ETA: 2:03 - loss: 0.140 - ETA: 2:03 - loss: 0.139 - ETA: 2:02 - loss: 0.139 - ETA: 2:02 - loss: 0.138 - ETA: 2:02 - loss: 0.138 - ETA: 2:02 - loss: 0.137 - ETA: 2:02 - loss: 0.137 - ETA: 2:01 - loss: 0.136 - ETA: 2:01 - loss: 0.136 - ETA: 2:00 - loss: 0.136 - ETA: 2:00 - loss: 0.135 - ETA: 2:00 - loss: 0.135 - ETA: 1:59 - loss: 0.134 - ETA: 1:59 - loss: 0.134 - ETA: 1:59 - loss: 0.133 - ETA: 1:59 - loss: 0.133 - ETA: 1:59 - loss: 0.132 - ETA: 1:59 - loss: 0.132 - ETA: 1:59 - loss: 0.131 - ETA: 1:58 - loss: 0.131 - ETA: 1:58 - loss: 0.130 - ETA: 1:58 - loss: 0.130 - ETA: 1:58 - loss: 0.129 - ETA: 1:57 - loss: 0.129 - ETA: 1:57 - loss: 0.129 - ETA: 1:57 - loss: 0.128 - ETA: 1:57 - loss: 0.128 - ETA: 1:56 - loss: 0.127 - ETA: 1:56 - loss: 0.127 - ETA: 1:56 - loss: 0.126 - ETA: 1:56 - loss: 0.126 - ETA: 1:55 - loss: 0.126 - ETA: 1:55 - loss: 0.126 - ETA: 1:55 - loss: 0.125 - ETA: 1:55 - loss: 0.125 - ETA: 1:55 - loss: 0.125 - ETA: 1:54 - loss: 0.124 - ETA: 1:54 - loss: 0.124 - ETA: 1:54 - loss: 0.124 - ETA: 1:53 - loss: 0.123 - ETA: 1:53 - loss: 0.123 - ETA: 1:53 - loss: 0.123 - ETA: 1:53 - loss: 0.123 - ETA: 1:53 - loss: 0.122 - ETA: 1:52 - loss: 0.122 - ETA: 1:52 - loss: 0.122 - ETA: 1:52 - loss: 0.121 - ETA: 1:51 - loss: 0.121 - ETA: 1:51 - loss: 0.120 - ETA: 1:52 - loss: 0.120 - ETA: 1:51 - loss: 0.120 - ETA: 1:51 - loss: 0.120 - ETA: 1:51 - loss: 0.119 - ETA: 1:50 - loss: 0.119 - ETA: 1:50 - loss: 0.119 - ETA: 1:50 - loss: 0.118 - ETA: 1:50 - loss: 0.118 - ETA: 1:50 - loss: 0.118 - ETA: 1:50 - loss: 0.118 - ETA: 1:50 - loss: 0.117 - ETA: 1:50 - loss: 0.117 - ETA: 1:50 - loss: 0.117 - ETA: 1:50 - loss: 0.117 - ETA: 1:49 - loss: 0.116 - ETA: 1:49 - loss: 0.116 - ETA: 1:49 - loss: 0.116 - ETA: 1:48 - loss: 0.116 - ETA: 1:48 - loss: 0.116 - ETA: 1:48 - loss: 0.115 - ETA: 1:48 - loss: 0.115 - ETA: 1:47 - loss: 0.115 - ETA: 1:47 - loss: 0.115 - ETA: 1:47 - loss: 0.115 - ETA: 1:47 - loss: 0.1150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d5a2ee902cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[EarlyStopping(monitor='val_loss', \n\u001b[1;32m     11\u001b[0m                                       \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                       verbose=1)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
