{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architectures\n",
    "- simple (encoder: lstm, decoder: lstm -> dense)\n",
    "- stacked_encoder (encoder: lstm -> lstm, decoder: lstm -> dense)\n",
    "- bistacked_encoder (encoder: bilstm -> lstm, decoder: lstm -> dense)\n",
    "- stacked_decoder (encoder: lstm, decoder: lstm -> lstm -> dense)\n",
    "- stacked (encoder: lstm -> lstm, decoder: lstm -> lstm -> dense)\n",
    "- bistacked (encoder: bilstm -> lstm, decoder: lstm -> lstm -> dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memory footprint support libraries/code\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# !pip install psutil\n",
    "# !pip install humanize\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/third-order/X_train.npy')\n",
    "y_train = np.load('./data/third-order/y_train.npy')\n",
    "X_valid = np.load('./data/third-order/X_valid.npy')\n",
    "y_valid = np.load('./data/third-order/y_valid.npy')\n",
    "X_test = np.load('./data/third-order/X_test.npy')\n",
    "y_test = np.load('./data/third-order/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, encoder_input_dim = X_train.shape[1], X_train.shape[2]\n",
    "Ty = y_train.shape[1]\n",
    "# we feed back only the target variable we are predicting\n",
    "decoder_input_dim = decoder_output_dim = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_encoder_input_data = X_train.copy()\n",
    "train_decoder_target_data = y_train.copy()\n",
    "train_decoder_input_data = shift(train_decoder_target_data[:, :, 0].reshape(\n",
    "                                y_train.shape[0], y_train.shape[1], decoder_input_dim), \n",
    "                           shift=[0, 1, 0], cval=-10)\n",
    "\n",
    "valid_encoder_input_data = X_valid.copy()\n",
    "valid_decoder_target_data = y_valid.copy()\n",
    "valid_decoder_input_data = shift(valid_decoder_target_data[:, :, 0].reshape(\n",
    "                                y_valid.shape[0], y_valid.shape[1], decoder_input_dim), \n",
    "                           shift=[0, 1, 0], cval=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "    return K.sum(((y_true[:, :, 0] - y_pred[:, :, 0]) ** 2) * (1-y_true[:, :, 1]), \n",
    "                  axis=-1) / (1 + K.sum((1-y_true[:, :, 1]), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=16, max_value=64, step=16)\n",
    "        \n",
    "        encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        dropout = Dropout(rate=hp.Float('dropout', 0, 0.5, \n",
    "                                        step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        \n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "\n",
    "        # We discard output and keep the states only.\n",
    "        _, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = SimpleSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedEncoderSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        encoder_latent_dim = hp.Int('encoder_latent_dim', min_value=32, \n",
    "                                    max_value=128, step=32)\n",
    "        shared_latent_dim = hp.Int('shared_latent_dim', min_value=32, \n",
    "                                   max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = LSTM(encoder_latent_dim, return_sequences=True, \n",
    "                              name='encoder_lstm_1')\n",
    "        encoder_dropout = Dropout(rate=hp.Float('encoder_dropout', 0, 0.7, \n",
    "                                        step=0.1, default=0.5))\n",
    "        encoder_lstm_2 = LSTM(shared_latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm = LSTM(shared_latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dropout = Dropout(rate=hp.Float('decoder_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # Obtain the outputs from the first encoder layer\n",
    "        encoder_out = encoder_lstm_1(encoder_inputs) \n",
    "        \n",
    "        # Pass the outputs through a dropout layer before \n",
    "        # feeding them to the next LSTM layer\n",
    "        encoder_out = encoder_dropout(encoder_out)\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm_2(encoder_out)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = decoder_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedEncoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='stacked-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiStacked encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiStackedEncoderSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        encoder_latent_dim = hp.Int('encoder_latent_dim', min_value=32, \n",
    "                                    max_value=128, step=32)\n",
    "        shared_latent_dim = hp.Int('shared_latent_dim', min_value=32, \n",
    "                                   max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = Bidirectional(LSTM(encoder_latent_dim, return_sequences=True, \n",
    "                              name='encoder_lstm_1'))\n",
    "        encoder_dropout = Dropout(rate=hp.Float('encoder_dropout', 0, 0.7, \n",
    "                                        step=0.1, default=0.5))\n",
    "        encoder_lstm_2 = LSTM(shared_latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm = LSTM(shared_latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dropout = Dropout(rate=hp.Float('decoder_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # Obtain the outputs from the first encoder layer\n",
    "        encoder_out = encoder_lstm_1(encoder_inputs) \n",
    "        \n",
    "        # Pass the outputs through a dropout layer before \n",
    "        # feeding them to the next LSTM layer\n",
    "        encoder_out = encoder_dropout(encoder_out)\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm_2(encoder_out)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = decoder_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = BiStackedEncoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='bistacked-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedDecoderSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        shared_latent_dim = hp.Int('shared_latent_dim', min_value=16, \n",
    "                                   max_value=64, step=16)\n",
    "        decoder_latent_dim = hp.Int('decoder_latent_dim', min_value=16, \n",
    "                                    max_value=64, step=16)\n",
    "        \n",
    "        encoder_lstm = LSTM(shared_latent_dim, return_state=True, \n",
    "                              name='encoder_lstm')\n",
    "        decoder_lstm_1 = LSTM(shared_latent_dim, return_sequences=True, \n",
    "                              name='decoder_lstm_1')\n",
    "        decoder_dropout_1 = Dropout(rate=hp.Float('decoder_dropout_1', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        decoder_lstm_2 = LSTM(decoder_latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm_2')\n",
    "        decoder_dropout_2 = Dropout(rate=hp.Float('decoder_dropout_2', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs = decoder_lstm_1(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = decoder_dropout_1(decoder_outputs)\n",
    "\n",
    "        # Apply LSTM again (stacked)\n",
    "        decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        decoder_outputs = decoder_dropout_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedDecoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='stacked-decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=16, max_value=64, \n",
    "                            step=16)\n",
    "        \n",
    "        encoder_lstm_1 = LSTM(latent_dim, return_sequences=True,\n",
    "                              name='encoder_lstm_1')\n",
    "        encoder_lstm_2 = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, \n",
    "                              name='decoder_lstm_1')\n",
    "        decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, \n",
    "                              return_state=True, name='decoder_lstm_2')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # First layer in the encoder\n",
    "        encoder_outputs = encoder_lstm_1(encoder_inputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        encoder_outputs = seq_dropout(encoder_outputs)\n",
    "        \n",
    "        # Pass the outputs to the next encoder layer, obtain h and c\n",
    "        _, h, c = encoder_lstm_2(encoder_outputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs = decoder_lstm_1(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply LSTM again (stacked)\n",
    "        decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "        \n",
    "        # Apply dense \n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='stacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiStacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiStackedSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=16, max_value=64, \n",
    "                            step=16)\n",
    "        \n",
    "        encoder_lstm_1 = Bidirectional(LSTM(latent_dim, return_sequences=True,\n",
    "                              name='encoder_lstm_1'))\n",
    "        encoder_lstm_2 = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, \n",
    "                              name='decoder_lstm_1')\n",
    "        decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, \n",
    "                              return_state=True, name='decoder_lstm_2')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # First layer in the encoder\n",
    "        encoder_outputs = encoder_lstm_1(encoder_inputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        encoder_outputs = seq_dropout(encoder_outputs)\n",
    "        \n",
    "        # Pass the outputs to the next encoder layer, obtain h and c\n",
    "        _, h, c = encoder_lstm_2(encoder_outputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs = decoder_lstm_1(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply LSTM again (stacked)\n",
    "        decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "        \n",
    "        # Apply dense \n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = BiStackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner', \n",
    "                     project_name='bistacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=100,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=10, \n",
    "                                      verbose=1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
