{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq model architectures:\n",
    "- simple (encoder: lstm, decoder: lstm -> dense)\n",
    "- stacked_encoder (encoder: lstm -> lstm, decoder: lstm -> dense)\n",
    "- bistacked_encoder (encoder: bilstm -> lstm, decoder: lstm -> dense)\n",
    "- stacked_decoder (encoder: lstm, decoder: lstm -> lstm -> dense)\n",
    "- stacked (encoder: lstm -> lstm, decoder: lstm -> lstm -> dense)\n",
    "- bistacked (encoder: bilstm -> lstm, decoder: lstm -> lstm -> dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memory footprint support libraries/code\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# !pip install psutil\n",
    "# !pip install humanize\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/zafir/miniconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_input_data = np.load('./data/third-order/seq2seq/train_encoder_input_data.npy')\n",
    "train_decoder_input_data = np.load('./data/third-order/seq2seq/train_decoder_input_data.npy')\n",
    "train_decoder_target_data = np.load('./data/third-order/seq2seq/train_decoder_target_data.npy')\n",
    "\n",
    "valid_encoder_input_data = np.load('./data/third-order/seq2seq/valid_encoder_input_data.npy')\n",
    "valid_decoder_input_data = np.load('./data/third-order/seq2seq/valid_decoder_input_data.npy')\n",
    "valid_decoder_target_data = np.load('./data/third-order/seq2seq/valid_decoder_target_data.npy')\n",
    "\n",
    "test_encoder_input_data = np.load('./data/third-order/seq2seq/test_encoder_input_data.npy')\n",
    "test_decoder_input_data = np.load('./data/third-order/seq2seq/test_decoder_input_data.npy')\n",
    "test_decoder_target_data = np.load('./data/third-order/seq2seq/test_decoder_target_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67396, 24, 23)\n",
      "(67396, 12, 23)\n",
      "(67396, 12, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_encoder_input_data.shape)\n",
    "print(train_decoder_input_data.shape)\n",
    "print(train_decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, encoder_input_dim = (train_encoder_input_data.shape[1], \n",
    "                         train_encoder_input_data.shape[2])\n",
    "    \n",
    "Ty, decoder_input_dim = (train_decoder_input_data.shape[1], \n",
    "                         train_decoder_input_data.shape[2])\n",
    "\n",
    "# we are predicting the pollution only, leave out the mask\n",
    "decoder_output_dim = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "    return K.sum(((y_true[:, :, 0] - y_pred[:, :, 0]) ** 2) * (1-y_true[:, :, 1]), \n",
    "                  axis=-1) / (1 + K.sum((1-y_true[:, :, 1]), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        \n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "\n",
    "        # We discard output and keep the states only.\n",
    "        _, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f504ea4b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f504ea4b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f504ea4b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f504ea4b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f504ea4b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f504ea4b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f504ea4b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f504ea4b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f504ea4b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f504ea4b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f504ea4b378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f504ea4b378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f504ea4b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f504ea4b400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f504ea4b400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f504ea4b400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = SimpleSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=250,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=20, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedEncoderSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = LSTM(latent_dim, return_sequences=True, \n",
    "                              name='encoder_lstm_1')\n",
    "        encoder_lstm_2 = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        \n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # Obtain the outputs from the first encoder layer\n",
    "        encoder_out = encoder_lstm_1(encoder_inputs) \n",
    "        \n",
    "        # Pass the outputs through a dropout layer before \n",
    "        # feeding them to the next LSTM layer\n",
    "        encoder_out = seq_dropout(encoder_out)\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm_2(encoder_out)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedEncoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='stacked-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=250,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=20, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiStacked encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiStackedEncoderSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = Bidirectional(LSTM(latent_dim, return_sequences=True, \n",
    "                              name='encoder_lstm_1'), merge_mode='concat')\n",
    "        encoder_lstm_2 = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # Obtain the outputs from the first encoder layer\n",
    "        encoder_out = encoder_lstm_1(encoder_inputs) \n",
    "        \n",
    "        # Pass the outputs through a dropout layer before \n",
    "        # feeding them to the next LSTM layer\n",
    "        encoder_out = seq_dropout(encoder_out)\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm_2(encoder_out)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs, _, _  = decoder_lstm(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7fe665934378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fe665934378>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7fe665934400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fe665934400>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = BiStackedEncoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='bistacked-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=250,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=20, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedDecoderSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm')\n",
    "        decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, \n",
    "                              name='decoder_lstm_1')\n",
    "        decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, \n",
    "                            return_state=True, name='decoder_lstm_2')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # We discard the output and keep the states only.\n",
    "        _, h, c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs = decoder_lstm_1(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply LSTM again (stacked)\n",
    "        decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "        \n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedDecoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='stacked-decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=250,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=20, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "6.0class StackedSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = LSTM(latent_dim, return_sequences=True,\n",
    "                              name='encoder_lstm_1')\n",
    "        encoder_lstm_2 = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, \n",
    "                              name='decoder_lstm_1')\n",
    "        decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, \n",
    "                              return_state=True, name='decoder_lstm_2')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # First layer in the encoder\n",
    "        encoder_outputs = encoder_lstm_1(encoder_inputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        encoder_outputs = seq_dropout(encoder_outputs)\n",
    "        \n",
    "        # Pass the outputs to the next encoder layer, obtain h and c\n",
    "        _, h, c = encoder_lstm_2(encoder_outputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs = decoder_lstm_1(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply LSTM again (stacked)\n",
    "        decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        decoder_outputs = dense_dropout(decoder_outputs)\n",
    "        \n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project local-keras-tuner/stacked/oracle.json\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "model_builder = StackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='stacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f2a81f8a0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f2a81f8a0d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f2a81f8a158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f2a81f8a158>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /home/zafir/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 67397 samples, validate on 3389 samples\n",
      "Epoch 1/100\n",
      "13504/67397 [=====>........................] - ETA: 42:48 - loss: 1.14 - ETA: 22:05 - loss: 1.03 - ETA: 15:08 - loss: 1.01 - ETA: 11:43 - loss: 0.98 - ETA: 9:37 - loss: 0.9483 - ETA: 8:10 - loss: 0.932 - ETA: 7:12 - loss: 0.945 - ETA: 6:33 - loss: 0.911 - ETA: 5:59 - loss: 0.890 - ETA: 5:33 - loss: 0.865 - ETA: 5:10 - loss: 0.845 - ETA: 4:53 - loss: 0.811 - ETA: 4:36 - loss: 0.805 - ETA: 4:22 - loss: 0.793 - ETA: 4:08 - loss: 0.784 - ETA: 3:58 - loss: 0.775 - ETA: 3:48 - loss: 0.769 - ETA: 3:42 - loss: 0.752 - ETA: 3:35 - loss: 0.746 - ETA: 3:27 - loss: 0.735 - ETA: 3:21 - loss: 0.724 - ETA: 3:14 - loss: 0.714 - ETA: 3:09 - loss: 0.701 - ETA: 3:04 - loss: 0.694 - ETA: 2:59 - loss: 0.683 - ETA: 2:49 - loss: 0.677 - ETA: 2:44 - loss: 0.669 - ETA: 2:41 - loss: 0.665 - ETA: 2:37 - loss: 0.661 - ETA: 2:35 - loss: 0.660 - ETA: 2:32 - loss: 0.649 - ETA: 2:25 - loss: 0.635 - ETA: 2:19 - loss: 0.626 - ETA: 2:17 - loss: 0.622 - ETA: 2:15 - loss: 0.617 - ETA: 2:10 - loss: 0.612 - ETA: 2:06 - loss: 0.601 - ETA: 2:04 - loss: 0.595 - ETA: 2:03 - loss: 0.590 - ETA: 2:01 - loss: 0.585 - ETA: 2:00 - loss: 0.580 - ETA: 1:59 - loss: 0.576 - ETA: 1:59 - loss: 0.569 - ETA: 1:57 - loss: 0.564 - ETA: 1:57 - loss: 0.561 - ETA: 1:53 - loss: 0.555 - ETA: 1:53 - loss: 0.551 - ETA: 1:52 - loss: 0.546 - ETA: 1:52 - loss: 0.544 - ETA: 1:51 - loss: 0.541 - ETA: 1:49 - loss: 0.536 - ETA: 1:48 - loss: 0.532 - ETA: 1:47 - loss: 0.531 - ETA: 1:46 - loss: 0.527 - ETA: 1:45 - loss: 0.524 - ETA: 1:44 - loss: 0.521 - ETA: 1:44 - loss: 0.518 - ETA: 1:41 - loss: 0.513 - ETA: 1:41 - loss: 0.509 - ETA: 1:40 - loss: 0.506 - ETA: 1:39 - loss: 0.503 - ETA: 1:39 - loss: 0.500 - ETA: 1:38 - loss: 0.500 - ETA: 1:38 - loss: 0.497 - ETA: 1:38 - loss: 0.495 - ETA: 1:38 - loss: 0.493 - ETA: 1:36 - loss: 0.489 - ETA: 1:36 - loss: 0.488 - ETA: 1:35 - loss: 0.486 - ETA: 1:35 - loss: 0.483 - ETA: 1:35 - loss: 0.481 - ETA: 1:35 - loss: 0.480 - ETA: 1:33 - loss: 0.476 - ETA: 1:33 - loss: 0.474 - ETA: 1:32 - loss: 0.472 - ETA: 1:32 - loss: 0.470 - ETA: 1:31 - loss: 0.469 - ETA: 1:31 - loss: 0.467 - ETA: 1:31 - loss: 0.466 - ETA: 1:31 - loss: 0.465 - ETA: 1:30 - loss: 0.463 - ETA: 1:30 - loss: 0.463 - ETA: 1:28 - loss: 0.459 - ETA: 1:28 - loss: 0.457 - ETA: 1:28 - loss: 0.455 - ETA: 1:27 - loss: 0.454 - ETA: 1:26 - loss: 0.451 - ETA: 1:26 - loss: 0.449 - ETA: 1:25 - loss: 0.448 - ETA: 1:25 - loss: 0.447 - ETA: 1:24 - loss: 0.444 - ETA: 1:24 - loss: 0.442 - ETA: 1:24 - loss: 0.440 - ETA: 1:23 - loss: 0.438 - ETA: 1:23 - loss: 0.437 - ETA: 1:22 - loss: 0.434 - ETA: 1:22 - loss: 0.433 - ETA: 1:21 - loss: 0.431 - ETA: 1:21 - loss: 0.429 - ETA: 1:20 - loss: 0.428 - ETA: 1:20 - loss: 0.428 - ETA: 1:20 - loss: 0.427 - ETA: 1:20 - loss: 0.426 - ETA: 1:20 - loss: 0.424 - ETA: 1:20 - loss: 0.422 - ETA: 1:19 - loss: 0.422 - ETA: 1:19 - loss: 0.421 - ETA: 1:19 - loss: 0.420 - ETA: 1:19 - loss: 0.419 - ETA: 1:18 - loss: 0.417 - ETA: 1:18 - loss: 0.416 - ETA: 1:18 - loss: 0.415 - ETA: 1:17 - loss: 0.415 - ETA: 1:17 - loss: 0.413 - ETA: 1:17 - loss: 0.413 - ETA: 1:17 - loss: 0.413 - ETA: 1:17 - loss: 0.411 - ETA: 1:16 - loss: 0.410 - ETA: 1:16 - loss: 0.409 - ETA: 1:16 - loss: 0.407 - ETA: 1:16 - loss: 0.406 - ETA: 1:16 - loss: 0.405 - ETA: 1:16 - loss: 0.404 - ETA: 1:16 - loss: 0.403 - ETA: 1:15 - loss: 0.402 - ETA: 1:15 - loss: 0.401 - ETA: 1:15 - loss: 0.401 - ETA: 1:15 - loss: 0.400 - ETA: 1:15 - loss: 0.399 - ETA: 1:14 - loss: 0.398 - ETA: 1:14 - loss: 0.398 - ETA: 1:14 - loss: 0.397 - ETA: 1:14 - loss: 0.396 - ETA: 1:14 - loss: 0.395 - ETA: 1:14 - loss: 0.394 - ETA: 1:14 - loss: 0.393 - ETA: 1:14 - loss: 0.392 - ETA: 1:13 - loss: 0.391 - ETA: 1:13 - loss: 0.390 - ETA: 1:13 - loss: 0.389 - ETA: 1:13 - loss: 0.388 - ETA: 1:13 - loss: 0.387 - ETA: 1:13 - loss: 0.386 - ETA: 1:13 - loss: 0.385 - ETA: 1:13 - loss: 0.384 - ETA: 1:13 - loss: 0.383 - ETA: 1:13 - loss: 0.382 - ETA: 1:13 - loss: 0.381 - ETA: 1:13 - loss: 0.380 - ETA: 1:12 - loss: 0.379 - ETA: 1:12 - loss: 0.378 - ETA: 1:12 - loss: 0.377 - ETA: 1:11 - loss: 0.375 - ETA: 1:11 - loss: 0.375 - ETA: 1:11 - loss: 0.374 - ETA: 1:11 - loss: 0.373 - ETA: 1:11 - loss: 0.373 - ETA: 1:11 - loss: 0.372 - ETA: 1:11 - loss: 0.372 - ETA: 1:11 - loss: 0.371 - ETA: 1:11 - loss: 0.370 - ETA: 1:11 - loss: 0.370 - ETA: 1:11 - loss: 0.369 - ETA: 1:10 - loss: 0.368 - ETA: 1:10 - loss: 0.367 - ETA: 1:10 - loss: 0.366 - ETA: 1:10 - loss: 0.365 - ETA: 1:10 - loss: 0.365 - ETA: 1:10 - loss: 0.364 - ETA: 1:10 - loss: 0.363 - ETA: 1:09 - loss: 0.362 - ETA: 1:09 - loss: 0.361 - ETA: 1:09 - loss: 0.360 - ETA: 1:09 - loss: 0.359 - ETA: 1:09 - loss: 0.359 - ETA: 1:09 - loss: 0.358 - ETA: 1:09 - loss: 0.357 - ETA: 1:08 - loss: 0.356 - ETA: 1:08 - loss: 0.356 - ETA: 1:08 - loss: 0.355 - ETA: 1:08 - loss: 0.355 - ETA: 1:08 - loss: 0.354 - ETA: 1:08 - loss: 0.354 - ETA: 1:08 - loss: 0.353 - ETA: 1:07 - loss: 0.353 - ETA: 1:07 - loss: 0.352 - ETA: 1:07 - loss: 0.352 - ETA: 1:07 - loss: 0.351 - ETA: 1:07 - loss: 0.351 - ETA: 1:07 - loss: 0.3510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5a2ee902cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[EarlyStopping(monitor='val_loss', \n\u001b[1;32m     11\u001b[0m                                       \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                       verbose=1)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=250,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=20, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiStacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiStackedSeq2Seq(HyperModel):\n",
    "\n",
    "    def __init__(self, Tx, Ty, encoder_input_dim, \n",
    "                 decoder_input_dim, decoder_output_dim):\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        \n",
    "    def build(self, hp):\n",
    "\n",
    "        # ------------------- SHARED LAYERS ---------------------\n",
    "        latent_dim = hp.Int('latent_dim', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        encoder_lstm_1 = Bidirectional(LSTM(latent_dim, return_sequences=True,\n",
    "                              name='encoder_lstm_1'), merge_mode='concat')\n",
    "        encoder_lstm_2 = LSTM(latent_dim, return_state=True, \n",
    "                              name='encoder_lstm_2')\n",
    "        decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, \n",
    "                              name='decoder_lstm_1')\n",
    "        decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, \n",
    "                              return_state=True, name='decoder_lstm_2')\n",
    "        decoder_dense = Dense(self.decoder_output_dim, \n",
    "                              activation='linear', name='decoder_dense')\n",
    "        seq_dropout = Dropout(rate=hp.Float('seq_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "        dense_dropout = Dropout(rate=hp.Float('dense_dropout', 0, 0.7, \n",
    "                                step=0.1, default=0.5))\n",
    "\n",
    "        \n",
    "        # ---------------------- MODEL ------------------------\n",
    "        # Define the inputs for the encoder\n",
    "        encoder_inputs = Input(shape=(self.Tx, self.encoder_input_dim), \n",
    "                               name='encoder_input')\n",
    "        \n",
    "        # First layer in the encoder\n",
    "        encoder_outputs = encoder_lstm_1(encoder_inputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        encoder_outputs = seq_dropout(encoder_outputs)\n",
    "        \n",
    "        # Pass the outputs to the next encoder layer, obtain h and c\n",
    "        _, h, c = encoder_lstm_2(encoder_outputs)\n",
    "\n",
    "        # Define an input for the decoder\n",
    "        decoder_inputs = Input(shape=(self.Ty, self.decoder_input_dim), \n",
    "                               name='decoder_input')\n",
    "\n",
    "        # Obtain all the outputs from the decoder (return_sequences = True)\n",
    "        decoder_outputs = decoder_lstm_1(decoder_inputs, initial_state=[h, c])\n",
    "\n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "\n",
    "        # Apply LSTM again (stacked)\n",
    "        decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs)\n",
    "        \n",
    "        # Apply dropout\n",
    "        decoder_outputs = seq_dropout(decoder_outputs)\n",
    "        \n",
    "        # Apply dense \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                      outputs=decoder_outputs)\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, \n",
    "                                                sampling='log'))\n",
    "        model.compile(optimizer=optimizer, loss=masked_mse)\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = BiStackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=1000,\n",
    "                     executions_per_trial=1,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='bistacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=64,\n",
    "             epochs=250,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=20, \n",
    "                                      verbose=1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
