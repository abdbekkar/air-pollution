{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq model architectures:\n",
    "- simple (encoder: lstm, decoder: lstm -> dense)\n",
    "- stacked_encoder (encoder: lstm -> lstm, decoder: lstm -> dense)\n",
    "- bistacked_encoder (encoder: bilstm -> lstm, decoder: lstm -> dense)\n",
    "- stacked_decoder (encoder: lstm, decoder: lstm -> lstm -> dense)\n",
    "- stacked (encoder: lstm -> lstm, decoder: lstm -> lstm -> dense)\n",
    "- bistacked (encoder: bilstm -> lstm, decoder: lstm -> lstm -> dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memory footprint support libraries/code\n",
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# !pip install psutil\n",
    "# !pip install humanize\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# import GPUtil as GPU\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#  process = psutil.Process(os.getpid())\n",
    "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd \"/gdrive/My Drive/air-pollution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/zafir/miniconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from seq2seq_models import * \n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_input_data = np.load('./data/third-order/Centar/train_encoder_input_data.npy')\n",
    "train_decoder_input_data = np.load('./data/third-order/Centar/train_decoder_input_data.npy')\n",
    "train_decoder_target_data = np.load('./data/third-order/Centar/train_decoder_target_data.npy')\n",
    "\n",
    "valid_encoder_input_data = np.load('./data/third-order/Centar/valid_encoder_input_data.npy')\n",
    "valid_decoder_input_data = np.load('./data/third-order/Centar/valid_decoder_input_data.npy')\n",
    "valid_decoder_target_data = np.load('./data/third-order/Centar/valid_decoder_target_data.npy')\n",
    "\n",
    "test_encoder_input_data = np.load('./data/third-order/Centar/test_encoder_input_data.npy')\n",
    "test_decoder_input_data = np.load('./data/third-order/Centar/test_decoder_input_data.npy')\n",
    "test_decoder_target_data = np.load('./data/third-order/Centar/test_decoder_target_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67396, 24, 23)\n",
      "(67396, 12, 21)\n",
      "(67396, 12, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_encoder_input_data.shape)\n",
    "print(train_decoder_input_data.shape)\n",
    "print(train_decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, encoder_input_dim = (train_encoder_input_data.shape[1], \n",
    "                         train_encoder_input_data.shape[2])\n",
    "    \n",
    "Ty, decoder_input_dim = (train_decoder_input_data.shape[1], \n",
    "                         train_decoder_input_data.shape[2])\n",
    "\n",
    "# we are predicting the pollution only, leave out the mask\n",
    "decoder_output_dim = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 250\n",
    "max_trials = 250\n",
    "executions_per_trial = 1\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = SimpleSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedEncoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='stacked-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiStacked encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = BiStackedEncoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='bistacked-encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedDecoderSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='stacked-decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = StackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='stacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiStacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_builder = BiStackedSeq2Seq(Tx, Ty, encoder_input_dim, \n",
    "                             decoder_input_dim, decoder_output_dim)\n",
    "\n",
    "tuner = RandomSearch(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=max_trials,\n",
    "                     executions_per_trial=executions_per_trial,\n",
    "                     directory='local-keras-tuner/seq2seq', \n",
    "                     project_name='bistacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuner.search(x=[train_encoder_input_data, \n",
    "                train_decoder_input_data], \n",
    "             y=train_decoder_target_data,\n",
    "             validation_data=([\n",
    "                valid_encoder_input_data,\n",
    "                valid_decoder_input_data],\n",
    "                valid_decoder_target_data),\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                      patience=patience, \n",
    "                                      verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
